{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_181\"; OpenJDK Runtime Environment (build 1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13); OpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode)\n",
      "  Starting server from /home/paperspace/anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp2xtkh862\n",
      "  JVM stdout: /tmp/tmp2xtkh862/h2o_paperspace_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp2xtkh862/h2o_paperspace_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.7</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>26 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_paperspace_4ifl06</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>22.22 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.7\n",
       "H2O cluster version age:    26 days\n",
       "H2O cluster name:           H2O_from_python_paperspace_4ifl06\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    22.22 Gb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(max_mem_size=\"25g\", nthreads=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewsV1db  reviewsV1.db  reviewsV2.db  reviewsV3.db\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../Databases/reviewsV1.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('../Databases/reviewsV1.db') as conn:\n",
    "    data = pd.read_sql_query('SELECT * FROM Review', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by='Time', inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "TRAIN_SIZE = int(data.shape[0] * 0.7)\n",
    "TEST_SIZE = data.shape[0] - TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254883"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109236"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[0: TRAIN_SIZE]\n",
    "data_test = data[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.word2vec import H2OWord2vecEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o import H2OFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/h2o/utils/shared_utils.py:177: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  data = _handle_python_lists(python_obj.as_matrix().tolist(), -1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "data_train = H2OFrame(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data_train['Text'].tokenize(\"\\\\W+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec Model Build progress: |██████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "w2v_model = H2OWord2vecEstimator(vec_size = 100, model_id = \"w2v.hex\")\n",
    "w2v_model.train(training_frame=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg W2V.ipynb  BOW -- Logistic Regression.ipynb  tfidf_best.model\r\n",
      "best.model     README.md\t\t\t TFIDF.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paperspace/Amazon-Review----Logistic-Regression/w2v.hex.json'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.save_model_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('super', 0.7557393908500671),\n",
       "             ('although', 0.749390184879303),\n",
       "             ('pack', 0.7356115579605103),\n",
       "             ('prefer', 0.7264364957809448),\n",
       "             ('mock', 0.7117513418197632)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.find_synonyms(\"tasty\", count = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('sadly', 0.7593790292739868),\n",
       "             ('sorely', 0.7421629428863525),\n",
       "             ('returning', 0.7421483993530273),\n",
       "             ('apprehensive', 0.7391559481620789),\n",
       "             ('buying', 0.7303898334503174)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.find_synonyms(\"disappointed\", count = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtrain = w2v_model.transform(corpus, aggregate_method = \"AVERAGE\")  # Performs average W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254883, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtrain['Label'] = data_train[\"Polarity\"].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'alpha': [0, .25, .5, .75, 1],\n",
    "    'lambda': [1, 0.5, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = H2OGeneralizedLinearEstimator(family = 'binomial', # Binomial for logistic regression\n",
    "                                    nfolds=10,\n",
    "                                    keep_cross_validation_predictions=True,\n",
    "                                    fold_assignment=\"stratified\",\n",
    "                                    standardize = True,\n",
    "                                    seed=42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = H2OGridSearch(model = glm, hyper_params = hyper_params,\n",
    "                     search_criteria = {'strategy': \"Cartesian\"})    # Cartesian for fitting all the hp combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "grid.train(y = \"Label\", training_frame = Dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combs = []\n",
    "for ids in grid.model_ids:\n",
    "    param_combs.append(grid.get_hyperparams_dict(ids, False))\n",
    "\n",
    "cv_results = []\n",
    "for iters, param in enumerate(param_combs):\n",
    "    res = grid._grid_json['cross_validation_metrics_summary'][iters].as_data_frame()\n",
    "    res.set_index('', inplace=True)\n",
    "#     print(param)\n",
    "    cvRes = res.T[['accuracy', 'f1', 'recall', 'precision']].loc['mean']\n",
    "    cvRes['alpha'] = param['alpha']\n",
    "    cvRes['lambda'] = param['lambda']\n",
    "    cv_results.append(cvRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(cv_results).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>alpha</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.89728844</td>\n",
       "      <td>0.94129634</td>\n",
       "      <td>0.9678962</td>\n",
       "      <td>0.91613555</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8972028</td>\n",
       "      <td>0.94129527</td>\n",
       "      <td>0.9686958</td>\n",
       "      <td>0.9154179</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.89721453</td>\n",
       "      <td>0.94129366</td>\n",
       "      <td>0.9685539</td>\n",
       "      <td>0.9155394</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.89721453</td>\n",
       "      <td>0.94129366</td>\n",
       "      <td>0.9685539</td>\n",
       "      <td>0.9155394</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.89721453</td>\n",
       "      <td>0.94129366</td>\n",
       "      <td>0.9685539</td>\n",
       "      <td>0.9155394</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy          f1     recall   precision  alpha   lambda\n",
       "1   0.89728844  0.94129634  0.9678962  0.91613555   0.50  0.00001\n",
       "6    0.8972028  0.94129527  0.9686958   0.9154179   0.00  0.00001\n",
       "9   0.89721453  0.94129366  0.9685539   0.9155394   1.00  0.00000\n",
       "11  0.89721453  0.94129366  0.9685539   0.9155394   0.25  0.00000\n",
       "7   0.89721453  0.94129366  0.9685539   0.9155394   0.75  0.00000"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='f1', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we can see that the best value of F1 score is from the alpha = 0.5 and the lambda = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = H2OGeneralizedLinearEstimator(family = 'binomial', # Binomial for logistic regression\n",
    "                                    nfolds=0,\n",
    "                                    keep_cross_validation_predictions=False,\n",
    "                                    standardize = True,\n",
    "                                    seed=42,\n",
    "                                    alpha=0.5,\n",
    "                                    lambda_=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "clf.train(y='Label', training_frame=Dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/h2o/utils/shared_utils.py:177: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  data = _handle_python_lists(python_obj.as_matrix().tolist(), -1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "data_test = H2OFrame(data_test)\n",
    "corpus = data_test['Text'].tokenize(\"\\\\W+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtest = w2v_model.transform(corpus, aggregate_method = \"AVERAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109236, 100)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Dtest['Label'] = data_test[\"Polarity\"].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">         C1</th><th style=\"text-align: right;\">        C2</th><th style=\"text-align: right;\">         C3</th><th style=\"text-align: right;\">        C4</th><th style=\"text-align: right;\">        C5</th><th style=\"text-align: right;\">         C6</th><th style=\"text-align: right;\">        C7</th><th style=\"text-align: right;\">        C8</th><th style=\"text-align: right;\">         C9</th><th style=\"text-align: right;\">      C10</th><th style=\"text-align: right;\">      C11</th><th style=\"text-align: right;\">        C12</th><th style=\"text-align: right;\">       C13</th><th style=\"text-align: right;\">        C14</th><th style=\"text-align: right;\">       C15</th><th style=\"text-align: right;\">        C16</th><th style=\"text-align: right;\">      C17</th><th style=\"text-align: right;\">       C18</th><th style=\"text-align: right;\">       C19</th><th style=\"text-align: right;\">        C20</th><th style=\"text-align: right;\">       C21</th><th style=\"text-align: right;\">        C22</th><th style=\"text-align: right;\">       C23</th><th style=\"text-align: right;\">        C24</th><th style=\"text-align: right;\">       C25</th><th style=\"text-align: right;\">       C26</th><th style=\"text-align: right;\">       C27</th><th style=\"text-align: right;\">       C28</th><th style=\"text-align: right;\">       C29</th><th style=\"text-align: right;\">       C30</th><th style=\"text-align: right;\">        C31</th><th style=\"text-align: right;\">       C32</th><th style=\"text-align: right;\">       C33</th><th style=\"text-align: right;\">      C34</th><th style=\"text-align: right;\">        C35</th><th style=\"text-align: right;\">         C36</th><th style=\"text-align: right;\">     C37</th><th style=\"text-align: right;\">        C38</th><th style=\"text-align: right;\">       C39</th><th style=\"text-align: right;\">        C40</th><th style=\"text-align: right;\">        C41</th><th style=\"text-align: right;\">       C42</th><th style=\"text-align: right;\">       C43</th><th style=\"text-align: right;\">      C44</th><th style=\"text-align: right;\">      C45</th><th style=\"text-align: right;\">       C46</th><th style=\"text-align: right;\">        C47</th><th style=\"text-align: right;\">        C48</th><th style=\"text-align: right;\">        C49</th><th style=\"text-align: right;\">        C50</th><th style=\"text-align: right;\">       C51</th><th style=\"text-align: right;\">       C52</th><th style=\"text-align: right;\">       C53</th><th style=\"text-align: right;\">      C54</th><th style=\"text-align: right;\">      C55</th><th style=\"text-align: right;\">      C56</th><th style=\"text-align: right;\">       C57</th><th style=\"text-align: right;\">        C58</th><th style=\"text-align: right;\">       C59</th><th style=\"text-align: right;\">       C60</th><th style=\"text-align: right;\">     C61</th><th style=\"text-align: right;\">       C62</th><th style=\"text-align: right;\">       C63</th><th style=\"text-align: right;\">      C64</th><th style=\"text-align: right;\">       C65</th><th style=\"text-align: right;\">      C66</th><th style=\"text-align: right;\">      C67</th><th style=\"text-align: right;\">      C68</th><th style=\"text-align: right;\">       C69</th><th style=\"text-align: right;\">      C70</th><th style=\"text-align: right;\">       C71</th><th style=\"text-align: right;\">        C72</th><th style=\"text-align: right;\">      C73</th><th style=\"text-align: right;\">        C74</th><th style=\"text-align: right;\">         C75</th><th style=\"text-align: right;\">     C76</th><th style=\"text-align: right;\">       C77</th><th style=\"text-align: right;\">         C78</th><th style=\"text-align: right;\">       C79</th><th style=\"text-align: right;\">        C80</th><th style=\"text-align: right;\">        C81</th><th style=\"text-align: right;\">      C82</th><th style=\"text-align: right;\">       C83</th><th style=\"text-align: right;\">       C84</th><th style=\"text-align: right;\">      C85</th><th style=\"text-align: right;\">         C86</th><th style=\"text-align: right;\">     C87</th><th style=\"text-align: right;\">       C88</th><th style=\"text-align: right;\">      C89</th><th style=\"text-align: right;\">       C90</th><th style=\"text-align: right;\">      C91</th><th style=\"text-align: right;\">      C92</th><th style=\"text-align: right;\">        C93</th><th style=\"text-align: right;\">      C94</th><th style=\"text-align: right;\">       C95</th><th style=\"text-align: right;\">       C96</th><th style=\"text-align: right;\">       C97</th><th style=\"text-align: right;\">       C98</th><th style=\"text-align: right;\">        C99</th><th style=\"text-align: right;\">      C100</th><th>Label   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">-0.0811165 </td><td style=\"text-align: right;\">-0.0803215</td><td style=\"text-align: right;\">-0.0336636 </td><td style=\"text-align: right;\">-0.103793 </td><td style=\"text-align: right;\">-0.0547823</td><td style=\"text-align: right;\">-0.0841875 </td><td style=\"text-align: right;\"> 0.0188438</td><td style=\"text-align: right;\"> 0.0274271</td><td style=\"text-align: right;\">-0.00481949</td><td style=\"text-align: right;\">0.0469253</td><td style=\"text-align: right;\">0.104655 </td><td style=\"text-align: right;\">-0.0302858 </td><td style=\"text-align: right;\">-0.121666 </td><td style=\"text-align: right;\">-0.00913039</td><td style=\"text-align: right;\">-0.014415 </td><td style=\"text-align: right;\">-0.0145939 </td><td style=\"text-align: right;\">0.180635 </td><td style=\"text-align: right;\">-0.0688314</td><td style=\"text-align: right;\">-0.0828794</td><td style=\"text-align: right;\"> 0.10184   </td><td style=\"text-align: right;\">-0.328082 </td><td style=\"text-align: right;\">-0.00637254</td><td style=\"text-align: right;\">-0.0942929</td><td style=\"text-align: right;\"> 0.0290757 </td><td style=\"text-align: right;\">0.0192483 </td><td style=\"text-align: right;\">-0.181837 </td><td style=\"text-align: right;\">-0.145791 </td><td style=\"text-align: right;\">-0.0879789</td><td style=\"text-align: right;\">-0.0638319</td><td style=\"text-align: right;\"> 0.0560504</td><td style=\"text-align: right;\">-0.055323  </td><td style=\"text-align: right;\"> 0.0186724</td><td style=\"text-align: right;\">-0.114894 </td><td style=\"text-align: right;\">0.127237 </td><td style=\"text-align: right;\">-0.036918  </td><td style=\"text-align: right;\">-0.100001   </td><td style=\"text-align: right;\">0.179494</td><td style=\"text-align: right;\">-0.075413  </td><td style=\"text-align: right;\">-0.0658221</td><td style=\"text-align: right;\"> 0.00109704</td><td style=\"text-align: right;\">-0.00473262</td><td style=\"text-align: right;\"> 0.0154825</td><td style=\"text-align: right;\">-0.213608 </td><td style=\"text-align: right;\">0.0271758</td><td style=\"text-align: right;\">0.146747 </td><td style=\"text-align: right;\">-0.0732614</td><td style=\"text-align: right;\">-0.0509814 </td><td style=\"text-align: right;\"> 0.119581  </td><td style=\"text-align: right;\"> 0.0332473 </td><td style=\"text-align: right;\">-0.16616   </td><td style=\"text-align: right;\"> 0.0510228</td><td style=\"text-align: right;\">-0.0520874</td><td style=\"text-align: right;\">-0.0369934</td><td style=\"text-align: right;\">-0.25704 </td><td style=\"text-align: right;\">0.0234957</td><td style=\"text-align: right;\">0.0231302</td><td style=\"text-align: right;\">-0.0292449</td><td style=\"text-align: right;\"> 0.0407036 </td><td style=\"text-align: right;\"> 0.054094 </td><td style=\"text-align: right;\">-0.0183176</td><td style=\"text-align: right;\">0.164926</td><td style=\"text-align: right;\">0.00462391</td><td style=\"text-align: right;\"> 0.0705556</td><td style=\"text-align: right;\">0.0375905</td><td style=\"text-align: right;\">-0.0389699</td><td style=\"text-align: right;\">-0.200092</td><td style=\"text-align: right;\">0.0838363</td><td style=\"text-align: right;\">0.0989617</td><td style=\"text-align: right;\">-0.0169785</td><td style=\"text-align: right;\">0.113406 </td><td style=\"text-align: right;\"> 0.0988472</td><td style=\"text-align: right;\"> 0.0365938 </td><td style=\"text-align: right;\">0.0380149</td><td style=\"text-align: right;\">-0.00543264</td><td style=\"text-align: right;\"> 3.05288e-06</td><td style=\"text-align: right;\">0.208588</td><td style=\"text-align: right;\"> 0.146993 </td><td style=\"text-align: right;\"> 0.165111   </td><td style=\"text-align: right;\"> 0.0393786</td><td style=\"text-align: right;\">-0.0629135 </td><td style=\"text-align: right;\">-0.0355512 </td><td style=\"text-align: right;\">0.14917  </td><td style=\"text-align: right;\"> 0.013998 </td><td style=\"text-align: right;\"> 0.0473533</td><td style=\"text-align: right;\">0.122279 </td><td style=\"text-align: right;\"> 0.0329617  </td><td style=\"text-align: right;\">0.139322</td><td style=\"text-align: right;\">-0.107491 </td><td style=\"text-align: right;\">0.0479625</td><td style=\"text-align: right;\">-0.063389 </td><td style=\"text-align: right;\">0.152561 </td><td style=\"text-align: right;\">-0.170565</td><td style=\"text-align: right;\"> 0.105882  </td><td style=\"text-align: right;\">0.103273 </td><td style=\"text-align: right;\">-0.142177 </td><td style=\"text-align: right;\">-0.0667417</td><td style=\"text-align: right;\">-0.173864 </td><td style=\"text-align: right;\">-0.0490656</td><td style=\"text-align: right;\"> 0.00917091</td><td style=\"text-align: right;\">-0.0363559</td><td>positive</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 0.0205021 </td><td style=\"text-align: right;\">-0.165466 </td><td style=\"text-align: right;\"> 0.0113958 </td><td style=\"text-align: right;\">-0.13754  </td><td style=\"text-align: right;\">-0.127519 </td><td style=\"text-align: right;\"> 0.00323893</td><td style=\"text-align: right;\">-0.143967 </td><td style=\"text-align: right;\">-0.170892 </td><td style=\"text-align: right;\"> 0.1052    </td><td style=\"text-align: right;\">0.0703633</td><td style=\"text-align: right;\">0.113251 </td><td style=\"text-align: right;\">-0.062599  </td><td style=\"text-align: right;\">-0.0376514</td><td style=\"text-align: right;\">-0.0557374 </td><td style=\"text-align: right;\"> 0.101851 </td><td style=\"text-align: right;\"> 0.0541932 </td><td style=\"text-align: right;\">0.0129429</td><td style=\"text-align: right;\"> 0.0119299</td><td style=\"text-align: right;\">-0.0371769</td><td style=\"text-align: right;\"> 0.0041082 </td><td style=\"text-align: right;\">-0.0655403</td><td style=\"text-align: right;\">-0.0723812 </td><td style=\"text-align: right;\">-0.124848 </td><td style=\"text-align: right;\">-0.0997183 </td><td style=\"text-align: right;\">0.00295157</td><td style=\"text-align: right;\">-0.174578 </td><td style=\"text-align: right;\">-0.0827804</td><td style=\"text-align: right;\"> 0.0724277</td><td style=\"text-align: right;\">-0.0667448</td><td style=\"text-align: right;\">-0.0317697</td><td style=\"text-align: right;\">-0.0226917 </td><td style=\"text-align: right;\">-0.0859436</td><td style=\"text-align: right;\">-0.202249 </td><td style=\"text-align: right;\">0.175156 </td><td style=\"text-align: right;\"> 0.163163  </td><td style=\"text-align: right;\"> 0.117243   </td><td style=\"text-align: right;\">0.167959</td><td style=\"text-align: right;\"> 0.175641  </td><td style=\"text-align: right;\">-0.106399 </td><td style=\"text-align: right;\">-0.156009  </td><td style=\"text-align: right;\">-0.105977  </td><td style=\"text-align: right;\">-0.0349188</td><td style=\"text-align: right;\">-0.0252956</td><td style=\"text-align: right;\">0.121822 </td><td style=\"text-align: right;\">0.0197896</td><td style=\"text-align: right;\"> 0.119748 </td><td style=\"text-align: right;\">-0.0531078 </td><td style=\"text-align: right;\"> 0.208683  </td><td style=\"text-align: right;\"> 0.0756448 </td><td style=\"text-align: right;\"> 0.199906  </td><td style=\"text-align: right;\">-0.113473 </td><td style=\"text-align: right;\"> 0.0512793</td><td style=\"text-align: right;\">-0.0994539</td><td style=\"text-align: right;\">-0.142196</td><td style=\"text-align: right;\">0.0471209</td><td style=\"text-align: right;\">0.161815 </td><td style=\"text-align: right;\">-0.0203249</td><td style=\"text-align: right;\"> 0.0278624 </td><td style=\"text-align: right;\">-0.0229132</td><td style=\"text-align: right;\">-0.026676 </td><td style=\"text-align: right;\">0.174203</td><td style=\"text-align: right;\">0.0618324 </td><td style=\"text-align: right;\">-0.147551 </td><td style=\"text-align: right;\">0.267534 </td><td style=\"text-align: right;\">-0.0361523</td><td style=\"text-align: right;\">-0.125435</td><td style=\"text-align: right;\">0.163924 </td><td style=\"text-align: right;\">0.112849 </td><td style=\"text-align: right;\">-0.134062 </td><td style=\"text-align: right;\">0.132554 </td><td style=\"text-align: right;\">-0.0427346</td><td style=\"text-align: right;\"> 0.0600259 </td><td style=\"text-align: right;\">0.10593  </td><td style=\"text-align: right;\"> 0.198305  </td><td style=\"text-align: right;\">-0.0672954  </td><td style=\"text-align: right;\">0.101777</td><td style=\"text-align: right;\">-0.107409 </td><td style=\"text-align: right;\">-0.0701598  </td><td style=\"text-align: right;\">-0.0980992</td><td style=\"text-align: right;\">-0.0935637 </td><td style=\"text-align: right;\"> 0.00833548</td><td style=\"text-align: right;\">0.265662 </td><td style=\"text-align: right;\"> 0.0392818</td><td style=\"text-align: right;\">-0.0897258</td><td style=\"text-align: right;\">0.107489 </td><td style=\"text-align: right;\">-0.0741501  </td><td style=\"text-align: right;\">0.135833</td><td style=\"text-align: right;\"> 0.0640829</td><td style=\"text-align: right;\">0.0800151</td><td style=\"text-align: right;\"> 0.122526 </td><td style=\"text-align: right;\">0.0461561</td><td style=\"text-align: right;\">-0.128246</td><td style=\"text-align: right;\">-0.141923  </td><td style=\"text-align: right;\">0.11436  </td><td style=\"text-align: right;\">-0.155642 </td><td style=\"text-align: right;\"> 0.134814 </td><td style=\"text-align: right;\"> 0.0989109</td><td style=\"text-align: right;\">-0.0525174</td><td style=\"text-align: right;\">-0.0965649 </td><td style=\"text-align: right;\">-0.073218 </td><td>positive</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.0300266 </td><td style=\"text-align: right;\">-0.0774715</td><td style=\"text-align: right;\"> 0.0158763 </td><td style=\"text-align: right;\"> 0.0138112</td><td style=\"text-align: right;\"> 0.0483541</td><td style=\"text-align: right;\">-0.012576  </td><td style=\"text-align: right;\">-0.0465112</td><td style=\"text-align: right;\">-0.043096 </td><td style=\"text-align: right;\">-0.0182889 </td><td style=\"text-align: right;\">0.0132047</td><td style=\"text-align: right;\">0.0920811</td><td style=\"text-align: right;\">-0.0571766 </td><td style=\"text-align: right;\">-0.0966778</td><td style=\"text-align: right;\">-0.0513781 </td><td style=\"text-align: right;\"> 0.0435777</td><td style=\"text-align: right;\"> 0.054261  </td><td style=\"text-align: right;\">0.135046 </td><td style=\"text-align: right;\">-0.040214 </td><td style=\"text-align: right;\">-0.040473 </td><td style=\"text-align: right;\"> 0.00109839</td><td style=\"text-align: right;\">-0.122983 </td><td style=\"text-align: right;\">-0.0456106 </td><td style=\"text-align: right;\">-0.052722 </td><td style=\"text-align: right;\">-0.0122191 </td><td style=\"text-align: right;\">0.109677  </td><td style=\"text-align: right;\">-0.154464 </td><td style=\"text-align: right;\">-0.0370185</td><td style=\"text-align: right;\">-0.0156445</td><td style=\"text-align: right;\">-0.0232651</td><td style=\"text-align: right;\"> 0.0990379</td><td style=\"text-align: right;\">-0.00922851</td><td style=\"text-align: right;\"> 0.0204283</td><td style=\"text-align: right;\">-0.183302 </td><td style=\"text-align: right;\">0.0893498</td><td style=\"text-align: right;\"> 0.0693676 </td><td style=\"text-align: right;\">-0.000178192</td><td style=\"text-align: right;\">0.223722</td><td style=\"text-align: right;\"> 0.0534113 </td><td style=\"text-align: right;\">-0.128497 </td><td style=\"text-align: right;\"> 0.00244342</td><td style=\"text-align: right;\">-0.110544  </td><td style=\"text-align: right;\">-0.0625153</td><td style=\"text-align: right;\">-0.168856 </td><td style=\"text-align: right;\">0.124218 </td><td style=\"text-align: right;\">0.0545067</td><td style=\"text-align: right;\">-0.120823 </td><td style=\"text-align: right;\"> 0.00257057</td><td style=\"text-align: right;\"> 0.0791614 </td><td style=\"text-align: right;\">-0.00334674</td><td style=\"text-align: right;\"> 0.098529  </td><td style=\"text-align: right;\">-0.0199161</td><td style=\"text-align: right;\">-0.013678 </td><td style=\"text-align: right;\">-0.117751 </td><td style=\"text-align: right;\">-0.112827</td><td style=\"text-align: right;\">0.0467203</td><td style=\"text-align: right;\">0.169246 </td><td style=\"text-align: right;\"> 0.0249376</td><td style=\"text-align: right;\">-0.00472849</td><td style=\"text-align: right;\">-0.0143022</td><td style=\"text-align: right;\">-0.0794176</td><td style=\"text-align: right;\">0.149886</td><td style=\"text-align: right;\">0.0939491 </td><td style=\"text-align: right;\">-0.10148  </td><td style=\"text-align: right;\">0.0628088</td><td style=\"text-align: right;\">-0.0962232</td><td style=\"text-align: right;\">-0.144186</td><td style=\"text-align: right;\">0.0658782</td><td style=\"text-align: right;\">0.113765 </td><td style=\"text-align: right;\">-0.0771283</td><td style=\"text-align: right;\">0.0773388</td><td style=\"text-align: right;\"> 0.0690667</td><td style=\"text-align: right;\">-0.0286337 </td><td style=\"text-align: right;\">0.068038 </td><td style=\"text-align: right;\"> 0.0696626 </td><td style=\"text-align: right;\"> 0.0304662  </td><td style=\"text-align: right;\">0.233369</td><td style=\"text-align: right;\"> 0.10009  </td><td style=\"text-align: right;\">-0.000324637</td><td style=\"text-align: right;\">-0.0397532</td><td style=\"text-align: right;\">-0.00475507</td><td style=\"text-align: right;\"> 0.0705414 </td><td style=\"text-align: right;\">0.0771543</td><td style=\"text-align: right;\">-0.0296498</td><td style=\"text-align: right;\">-0.0431993</td><td style=\"text-align: right;\">0.0790168</td><td style=\"text-align: right;\">-0.00647494 </td><td style=\"text-align: right;\">0.127454</td><td style=\"text-align: right;\">-0.10165  </td><td style=\"text-align: right;\">0.0876053</td><td style=\"text-align: right;\">-0.0443461</td><td style=\"text-align: right;\">0.125389 </td><td style=\"text-align: right;\">-0.123542</td><td style=\"text-align: right;\"> 0.0227924 </td><td style=\"text-align: right;\">0.171478 </td><td style=\"text-align: right;\">-0.094382 </td><td style=\"text-align: right;\"> 0.0617737</td><td style=\"text-align: right;\">-0.0219504</td><td style=\"text-align: right;\">-0.0441576</td><td style=\"text-align: right;\"> 0.0518979 </td><td style=\"text-align: right;\"> 0.0159508</td><td>positive</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.00373758</td><td style=\"text-align: right;\">-0.180687 </td><td style=\"text-align: right;\"> 0.00534436</td><td style=\"text-align: right;\"> 0.0372322</td><td style=\"text-align: right;\">-0.0233362</td><td style=\"text-align: right;\"> 0.0339849 </td><td style=\"text-align: right;\"> 0.0202284</td><td style=\"text-align: right;\">-0.0440014</td><td style=\"text-align: right;\"> 0.0549587 </td><td style=\"text-align: right;\">0.0832781</td><td style=\"text-align: right;\">0.1053   </td><td style=\"text-align: right;\">-0.00739376</td><td style=\"text-align: right;\">-0.0741288</td><td style=\"text-align: right;\">-0.0716986 </td><td style=\"text-align: right;\"> 0.0886715</td><td style=\"text-align: right;\"> 0.00738196</td><td style=\"text-align: right;\">0.129294 </td><td style=\"text-align: right;\">-0.107934 </td><td style=\"text-align: right;\">-0.0209502</td><td style=\"text-align: right;\"> 0.0643498 </td><td style=\"text-align: right;\">-0.124082 </td><td style=\"text-align: right;\">-0.0224766 </td><td style=\"text-align: right;\">-0.0430142</td><td style=\"text-align: right;\">-0.0392409 </td><td style=\"text-align: right;\">0.102203  </td><td style=\"text-align: right;\">-0.046844 </td><td style=\"text-align: right;\"> 0.04392  </td><td style=\"text-align: right;\"> 0.0640543</td><td style=\"text-align: right;\"> 0.0229777</td><td style=\"text-align: right;\">-0.0469806</td><td style=\"text-align: right;\">-0.0533902 </td><td style=\"text-align: right;\">-0.0659166</td><td style=\"text-align: right;\">-0.0900956</td><td style=\"text-align: right;\">0.0985171</td><td style=\"text-align: right;\"> 0.00989937</td><td style=\"text-align: right;\">-0.0846132  </td><td style=\"text-align: right;\">0.170755</td><td style=\"text-align: right;\">-0.00939771</td><td style=\"text-align: right;\">-0.102259 </td><td style=\"text-align: right;\">-0.0194039 </td><td style=\"text-align: right;\">-0.106857  </td><td style=\"text-align: right;\">-0.0819121</td><td style=\"text-align: right;\">-0.0460772</td><td style=\"text-align: right;\">0.0543467</td><td style=\"text-align: right;\">0.136909 </td><td style=\"text-align: right;\">-0.056267 </td><td style=\"text-align: right;\">-0.0228944 </td><td style=\"text-align: right;\"> 0.0072829 </td><td style=\"text-align: right;\"> 0.0536907 </td><td style=\"text-align: right;\"> 0.00243512</td><td style=\"text-align: right;\">-0.0183058</td><td style=\"text-align: right;\">-0.0132267</td><td style=\"text-align: right;\"> 0.0391507</td><td style=\"text-align: right;\">-0.172441</td><td style=\"text-align: right;\">0.0568884</td><td style=\"text-align: right;\">0.0801557</td><td style=\"text-align: right;\"> 0.0500506</td><td style=\"text-align: right;\"> 0.0208112 </td><td style=\"text-align: right;\"> 0.11718  </td><td style=\"text-align: right;\">-0.122427 </td><td style=\"text-align: right;\">0.124398</td><td style=\"text-align: right;\">0.127346  </td><td style=\"text-align: right;\">-0.0553345</td><td style=\"text-align: right;\">0.0543196</td><td style=\"text-align: right;\">-0.0896683</td><td style=\"text-align: right;\">-0.146269</td><td style=\"text-align: right;\">0.13297  </td><td style=\"text-align: right;\">0.0910446</td><td style=\"text-align: right;\">-0.0297654</td><td style=\"text-align: right;\">0.0671919</td><td style=\"text-align: right;\"> 0.0566812</td><td style=\"text-align: right;\"> 0.00947502</td><td style=\"text-align: right;\">0.0663402</td><td style=\"text-align: right;\"> 0.0464224 </td><td style=\"text-align: right;\">-0.124017   </td><td style=\"text-align: right;\">0.105508</td><td style=\"text-align: right;\"> 0.0574148</td><td style=\"text-align: right;\">-0.00515434 </td><td style=\"text-align: right;\"> 0.0167618</td><td style=\"text-align: right;\">-0.0389177 </td><td style=\"text-align: right;\">-0.0386788 </td><td style=\"text-align: right;\">0.0938291</td><td style=\"text-align: right;\">-0.0548251</td><td style=\"text-align: right;\">-0.0200181</td><td style=\"text-align: right;\">0.110357 </td><td style=\"text-align: right;\">-0.115052   </td><td style=\"text-align: right;\">0.198284</td><td style=\"text-align: right;\">-0.0521946</td><td style=\"text-align: right;\">0.147442 </td><td style=\"text-align: right;\">-0.0335026</td><td style=\"text-align: right;\">0.242455 </td><td style=\"text-align: right;\">-0.159285</td><td style=\"text-align: right;\"> 0.055382  </td><td style=\"text-align: right;\">0.0448773</td><td style=\"text-align: right;\">-0.0409257</td><td style=\"text-align: right;\">-0.115868 </td><td style=\"text-align: right;\">-0.124268 </td><td style=\"text-align: right;\">-0.0223679</td><td style=\"text-align: right;\"> 0.130964  </td><td style=\"text-align: right;\">-0.0357328</td><td>positive</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.058977  </td><td style=\"text-align: right;\">-0.131072 </td><td style=\"text-align: right;\">-0.0527665 </td><td style=\"text-align: right;\">-0.0865414</td><td style=\"text-align: right;\">-0.0161196</td><td style=\"text-align: right;\">-0.0192357 </td><td style=\"text-align: right;\">-0.0505091</td><td style=\"text-align: right;\"> 0.0324884</td><td style=\"text-align: right;\"> 0.0724568 </td><td style=\"text-align: right;\">0.0281864</td><td style=\"text-align: right;\">0.129099 </td><td style=\"text-align: right;\">-0.0572646 </td><td style=\"text-align: right;\">-0.0352554</td><td style=\"text-align: right;\">-0.0149479 </td><td style=\"text-align: right;\">-0.0636034</td><td style=\"text-align: right;\"> 0.048542  </td><td style=\"text-align: right;\">0.0310397</td><td style=\"text-align: right;\"> 0.0358071</td><td style=\"text-align: right;\">-0.0913153</td><td style=\"text-align: right;\">-0.056166  </td><td style=\"text-align: right;\">-0.111529 </td><td style=\"text-align: right;\"> 0.0319539 </td><td style=\"text-align: right;\">-0.0525935</td><td style=\"text-align: right;\"> 0.00284119</td><td style=\"text-align: right;\">0.09313   </td><td style=\"text-align: right;\">-0.0869873</td><td style=\"text-align: right;\">-0.0324177</td><td style=\"text-align: right;\">-0.0202552</td><td style=\"text-align: right;\"> 0.04047  </td><td style=\"text-align: right;\"> 0.058133 </td><td style=\"text-align: right;\"> 0.00821839</td><td style=\"text-align: right;\"> 0.0655714</td><td style=\"text-align: right;\">-0.180545 </td><td style=\"text-align: right;\">0.0810469</td><td style=\"text-align: right;\"> 0.0745845 </td><td style=\"text-align: right;\">-0.115295   </td><td style=\"text-align: right;\">0.196244</td><td style=\"text-align: right;\"> 0.117471  </td><td style=\"text-align: right;\">-0.238035 </td><td style=\"text-align: right;\">-0.0394386 </td><td style=\"text-align: right;\">-0.176513  </td><td style=\"text-align: right;\"> 0.0131177</td><td style=\"text-align: right;\">-0.193768 </td><td style=\"text-align: right;\">0.076535 </td><td style=\"text-align: right;\">0.103351 </td><td style=\"text-align: right;\">-0.121202 </td><td style=\"text-align: right;\"> 0.0941532 </td><td style=\"text-align: right;\">-0.00437828</td><td style=\"text-align: right;\">-0.100062  </td><td style=\"text-align: right;\"> 0.0766182 </td><td style=\"text-align: right;\">-0.0411809</td><td style=\"text-align: right;\">-0.0175017</td><td style=\"text-align: right;\">-0.0428799</td><td style=\"text-align: right;\">-0.162121</td><td style=\"text-align: right;\">0.0180615</td><td style=\"text-align: right;\">0.0393091</td><td style=\"text-align: right;\"> 0.0561416</td><td style=\"text-align: right;\">-0.0158448 </td><td style=\"text-align: right;\">-0.0264854</td><td style=\"text-align: right;\">-0.0995744</td><td style=\"text-align: right;\">0.136804</td><td style=\"text-align: right;\">0.0721665 </td><td style=\"text-align: right;\">-0.113975 </td><td style=\"text-align: right;\">0.0321404</td><td style=\"text-align: right;\">-0.163044 </td><td style=\"text-align: right;\">-0.181728</td><td style=\"text-align: right;\">0.137097 </td><td style=\"text-align: right;\">0.134314 </td><td style=\"text-align: right;\">-0.0979797</td><td style=\"text-align: right;\">0.162572 </td><td style=\"text-align: right;\"> 0.0229825</td><td style=\"text-align: right;\"> 0.0191574 </td><td style=\"text-align: right;\">0.0320695</td><td style=\"text-align: right;\">-0.0662178 </td><td style=\"text-align: right;\">-0.0520614  </td><td style=\"text-align: right;\">0.214593</td><td style=\"text-align: right;\"> 0.125183 </td><td style=\"text-align: right;\">-0.0311344  </td><td style=\"text-align: right;\"> 0.0601311</td><td style=\"text-align: right;\">-0.0460493 </td><td style=\"text-align: right;\"> 0.0119002 </td><td style=\"text-align: right;\">0.140013 </td><td style=\"text-align: right;\">-0.0932242</td><td style=\"text-align: right;\">-0.0355831</td><td style=\"text-align: right;\">0.146309 </td><td style=\"text-align: right;\"> 0.000989272</td><td style=\"text-align: right;\">0.123004</td><td style=\"text-align: right;\">-0.0765913</td><td style=\"text-align: right;\">0.101531 </td><td style=\"text-align: right;\">-0.0590904</td><td style=\"text-align: right;\">0.0240321</td><td style=\"text-align: right;\">-0.140105</td><td style=\"text-align: right;\"> 0.00570312</td><td style=\"text-align: right;\">0.116393 </td><td style=\"text-align: right;\">-0.132099 </td><td style=\"text-align: right;\"> 0.0821007</td><td style=\"text-align: right;\">-0.127014 </td><td style=\"text-align: right;\">-0.0761184</td><td style=\"text-align: right;\">-0.0450169 </td><td style=\"text-align: right;\"> 0.0649057</td><td>positive</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "predict = clf.predict(Dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>predict  </th><th>negative             </th><th>positive             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum     </td><td>real                 </td><td>real                 </td></tr>\n",
       "<tr><td>mins   </td><td>         </td><td>6.218323148621252e-07</td><td>3.916595841314959e-06</td></tr>\n",
       "<tr><td>mean   </td><td>         </td><td>0.16338188782043545  </td><td>0.8366181121795644   </td></tr>\n",
       "<tr><td>maxs   </td><td>         </td><td>0.9999960834041587   </td><td>0.9999993781676851   </td></tr>\n",
       "<tr><td>sigma  </td><td>         </td><td>0.23520870436929783  </td><td>0.2352087043692978   </td></tr>\n",
       "<tr><td>zeros  </td><td>         </td><td>0                    </td><td>0                    </td></tr>\n",
       "<tr><td>missing</td><td>0        </td><td>0                    </td><td>0                    </td></tr>\n",
       "<tr><td>0      </td><td>positive </td><td>0.0654132321035984   </td><td>0.9345867678964016   </td></tr>\n",
       "<tr><td>1      </td><td>positive </td><td>0.25098149234069     </td><td>0.74901850765931     </td></tr>\n",
       "<tr><td>2      </td><td>positive </td><td>0.108727675662454    </td><td>0.891272324337546    </td></tr>\n",
       "<tr><td>3      </td><td>positive </td><td>0.13933853168261034  </td><td>0.8606614683173897   </td></tr>\n",
       "<tr><td>4      </td><td>positive </td><td>0.02378477544738189  </td><td>0.9762152245526181   </td></tr>\n",
       "<tr><td>5      </td><td>positive </td><td>0.02658636549910709  </td><td>0.9734136345008929   </td></tr>\n",
       "<tr><td>6      </td><td>positive </td><td>0.3690686909217811   </td><td>0.6309313090782189   </td></tr>\n",
       "<tr><td>7      </td><td>positive </td><td>0.008569651973560188 </td><td>0.9914303480264398   </td></tr>\n",
       "<tr><td>8      </td><td>positive </td><td>0.055648221217584615 </td><td>0.9443517787824154   </td></tr>\n",
       "<tr><td>9      </td><td>positive </td><td>0.2583225692289344   </td><td>0.7416774307710656   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = clf.model_performance(Dtest, train=False, valid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = mp.F1()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = mp.accuracy()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = mp.precision()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = PrettyTable(['f1', 'accuracy', 'precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.add_row([f1, ac, pre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|         f1         |      accuracy      |     precision      |\n",
      "+--------------------+--------------------+--------------------+\n",
      "| 0.9328953037483844 | 0.8860632026071991 | 0.9984358706986444 |\n",
      "+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5617146491016723: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>negative</b></td>\n",
       "<td><b>positive</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>negative</td>\n",
       "<td>10166.0</td>\n",
       "<td>8910.0</td>\n",
       "<td>0.4671</td>\n",
       "<td> (8910.0/19076.0)</td></tr>\n",
       "<tr><td>positive</td>\n",
       "<td>3550.0</td>\n",
       "<td>86610.0</td>\n",
       "<td>0.0394</td>\n",
       "<td> (3550.0/90160.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>13716.0</td>\n",
       "<td>95520.0</td>\n",
       "<td>0.1141</td>\n",
       "<td> (12460.0/109236.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "          negative    positive    Error    Rate\n",
       "--------  ----------  ----------  -------  ------------------\n",
       "negative  10166       8910        0.4671   (8910.0/19076.0)\n",
       "positive  3550        86610       0.0394   (3550.0/90160.0)\n",
       "Total     13716       95520       0.1141   (12460.0/109236.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_8e06 closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
